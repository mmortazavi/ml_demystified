{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv5 Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11.7\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov5.segment import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-4-15 Python-3.9.13 torch-2.0.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 220 layers, 21652358 parameters, 0 gradients, 69.8 GFLOPs\n",
      "image 1/1 C:\\Users\\majmo\\Git\\ml_demystified\\workshop\\computer_vision\\data\\test\\images\\DJI_0753_MP4-5_jpg.rf.be14f8318dbaa31cc2a3fae1ee4637b9.jpg: 384x640 (no detections), 416.7ms\n",
      "Speed: 0.0ms pre-process, 416.7ms inference, 0.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\majmo\\Git\\ml_demystified\\workshop\\computer_vision\\seg_custom_inference2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = predict.run(weights='seg_run\\\\weights\\\\best.pt',  # model.pt path(s)\n",
    "    source=r'data\\test\\images\\DJI_0753_MP4-5_jpg.rf.be14f8318dbaa31cc2a3fae1ee4637b9.jpg',  # file/dir/URL/glob/screen/0(webcam)\n",
    "    conf_thres=0.25,  # confidence threshold\n",
    "    iou_thres=0.45,  # NMS IOU threshold\n",
    "    view_img=False,  # show results\n",
    "    save_txt=False,  # save results to *.txt\n",
    "    save_conf=False,  # save confidences in --save-txt labels\n",
    "    save_crop=False,  # save cropped prediction boxes\n",
    "    project=project,  # save results to project/name\n",
    "    name='seg_custom_inference',  # save results to project/name\n",
    "    exist_ok=False,  # existing project/name ok, do not increment\n",
    "    line_thickness=3,  # bounding box thickness (pixels)\n",
    "    hide_labels=False,  # hide labels\n",
    "    hide_conf=False,  # hide confidences\n",
    "    half=False,  # use FP16 half-precision inference\n",
    "    dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "    vid_stride=1,  # video frame-rate stride\n",
    "    retina_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
